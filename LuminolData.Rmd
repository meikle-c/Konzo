---
title: "LuminolData"
author: "Cameron Meikle"
date: "2024-10-13"
output:
  pdf_document: default
  html_document: default
---

Library packages and set the knitr
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Change working directory here
knitr::opts_chunk$set(root.dir = "/Users/cameronmeikle/Desktop/UNR_RA_position/Projects/Konzo")
#We can!!!

library(knitr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(ggpubr)
library(purrr)

wd <- getwd()
```


Download and clean the datafile

13Oct2024 - Data is currently not manipulated in any way except for getting rid of the Dave samples 

```{r Datafile cleanup, echo=FALSE}
#Luminol Data
luminol_data <- read.csv(paste(wd,"/Luminol_field_data.csv", sep = ""))
#SubjectID_Data
Subject_ID_Data <- read.csv(paste(wd, "/KBS EDTA tube records_v1.csv", sep = ""))

metadata <- read.csv(paste(wd, "/KBS_Exam_metadata_V2.csv", sep = ""))

#Clean the Subject_ID_Data and combine to dataframes
Subject_ID_Data <- Subject_ID_Data %>% rename(Subject_Barcode = Subject.Barcode, 
                                              Sample_Type = Sample.Type) %>% select(Subject_Barcode,Sample_Type) %>% filter(Sample_Type != "Cassava Pit H2O") %>%
  filter(Sample_Type != "DRM CONTROL")

```


```{r Datafile cleanup2, echo=FALSE}
#Resolve duplication problem
Subject_ID_Data <- Subject_ID_Data %>% distinct(Subject_Barcode, .keep_all = TRUE)

#gives you the mean value between the two replicates for the luminol data
luminol_data2 <- luminol_data %>% 
  group_by(Subject.ID) %>% 
  summarize(
    `10` = mean(`X10.minutes`, na.rm = TRUE),
    `12.5` = mean(`X12.5.minutes`, na.rm = TRUE), 
    `15` = mean(`X15.minutes`, na.rm = TRUE),
    across(c(Location, Date, Order), first)
  )
#Change naming conventions of data
luminol_data <- luminol_data %>% rename( "15" = X15.minutes, "12.5" = X12.5.minutes,  "10" = X10.minutes)

#Filter out Dave Data
clean_luminol_data <- luminol_data2 %>% filter(Subject.ID != "Dave")

#Add Subject IDs
clean_luminol_data <- merge(clean_luminol_data, Subject_ID_Data, by.x = "Subject.ID", by.y = "Subject_Barcode")

#Add in Metadata - kept original Sample Type - can easily change by deselecting Sample_Type.y for Sample_Type.x
clean_luminol_data <- merge(clean_luminol_data, metadata, by = "Subject.ID") %>% select(-Sample_Type.y, -X, -Notes) %>% rename(Sample_Type = Sample_Type.x)

#Make sure severity is a factor and not a numerical value for downstream analysis
clean_luminol_data$Severity <- as.factor(clean_luminol_data$Severity)


Dave_Controls <- luminol_data %>% filter(Subject.ID == "Dave") %>% select(Subject.ID, Location, Date, Page, '10', '12.5', '15')

kable(Dave_Controls, caption = "Dave Controls")

```


Create basic histogram plots of the data
```{r overall histogram, echo=FALSE, warning=FALSE}
data_by_timepoint <- clean_luminol_data %>% pivot_longer( cols = c("10", "15", "12.5"), names_to = "Timepoint", values_to = "RFU")

#Overall histogram of values

ggplot(data_by_timepoint, aes(x = RFU, fill = Timepoint)) +
  geom_histogram(bins = 100) +
  labs(title = "Overall Histogram") +
  theme_minimal()

#Histogram by timepoint

unique_timepoints <- (c("10", "12.5", "15"))
for (timepoint in unique_timepoints) {
  df <- data_by_timepoint %>% filter(Timepoint == timepoint)
  
  histogram_plot <- ggplot(df, aes(x = RFU)) +
    geom_histogram(bins = 50) +
    labs(title = paste("Timepoint", timepoint, "minutes")) +
    theme_minimal()
  
  print(histogram_plot)
}

```

Create basic box plots of the data split by timepoint

```{r timepoint box plot, echo=FALSE, warning=FALSE}

ggplot(data_by_timepoint, aes(x = Timepoint, y = RFU, fill = Timepoint)) +
  geom_violin(show.legend = FALSE) +
  geom_boxplot(width = 0.2, show.legend = FALSE) +
  stat_compare_means(method = "anova") +
  theme_minimal()

```


Based on the above graph, I think it is okay to say that we will restrict to minute 15 for the long term analysis. I kept everything in loops that include all timepoints at the moment but that can easily be changed.

I then break down the spread by location. Theoretically all locations should look similar. However, there is 
```{r, warnings=FALSE, message=FALSE, echo=FALSE}

for (timepoint in unique_timepoints) {
  df <- data_by_timepoint %>% filter(Timepoint == timepoint)
  
  box_plot <- ggplot(df, aes(x = Location, y = RFU)) +
    geom_violin() +
  geom_boxplot(width = 0.2) +
    labs(title = paste("Timepoint", timepoint, "Minutes")) +
    stat_compare_means(method = "anova") +
    theme_minimal()
  
  print(box_plot)
  
  df_Control_only <- df %>% filter(Sample_Type == "Control")
  
   box_plot_Control <- ggplot(df_Control_only, aes(x = Location, y = RFU)) +
    geom_violin() +
  geom_boxplot(width = 0.2) +
    labs(title = paste("Timepoint", timepoint, "Minutes_Control Only")) +
    stat_compare_means(method = "anova") +
    theme_minimal()
   
   print(box_plot_Control)
  
  anova <- aov(RFU ~ Location, df)
  
  print(summary(anova))
  
}

SamplesPerLocation <- clean_luminol_data %>% count(Location)
kable(SamplesPerLocation, caption = "Samples per location")
```


Boxplot comparing the controls versus diseased

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
#Overall graphic
ggplot(data_by_timepoint, aes(x = Sample_Type, y = RFU)) +
  geom_boxplot() +
  stat_compare_means(method = "t.test") +
  theme_minimal()

#Split by timepoint
for (timepoint in unique_timepoints) {
  df <- data_by_timepoint %>% filter(Timepoint == timepoint)
  
  box_plot <- ggplot(df, aes(x = Sample_Type, y = RFU, fill = Sample_Type)) +
    geom_violin() +
  geom_boxplot(width = 0.2, show.legend = FALSE) +
  labs(title = paste("Timepoint", timepoint, "Minutes")) +
  stat_compare_means(method = "t.test") +
    theme_minimal()

  
  print(box_plot)
}

SamplesPerStatus <- clean_luminol_data %>% count(Sample_Type)
kable(SamplesPerStatus, caption = "Samples per Disease Status")

```

Since the above is significant, we are going to do the analysis on the 15 minute timepoint and split by location


```{r, echo=FALSE, warning=FALSE, message=FALSE}
unique_locations <- unique(data_by_timepoint$Location)

for (location in unique_locations) {
  df <- data_by_timepoint %>% filter(Timepoint == "15") %>% filter(Location == location)
  
  box_plot <- ggplot(df, aes(x = Sample_Type, y = RFU)) +
  geom_boxplot() +
  labs(title = paste("15 Minute Timepoint at", location)) +
  stat_compare_means(method = "t.test") +
    theme_minimal()
  
  print(box_plot)
  
  samples_df <- clean_luminol_data %>% filter(Location == location)
  SamplesPerStatus <- samples_df %>% count(Sample_Type)
  print(kable(SamplesPerStatus, caption = paste("Samples per Disease Status at", location)))
  
}

```




We now have a rough draft csv of the metadata. These were added to the first block of code on 7Nov2024.
The first thing to do is to look at the age distribution between groups and then do a correlation between RFU and age to test for age as a confounder.

```{r, ageinfo, echo=FALSE, warning=FALSE, message=FALSE}
#Restrict to only the 15 minute timepoint
FifteenMinutedataframe <- data_by_timepoint %>% filter(Timepoint == "15")

#Colored histogram 
ggplot(FifteenMinutedataframe, aes(x = Age, fill = Sample_Type)) +
  geom_histogram(bins = 30) +
  theme_minimal()

Sample_Types <- unique(FifteenMinutedataframe$Sample_Type)

for (status in Sample_Types) {
  df <- FifteenMinutedataframe %>% filter (Sample_Type == status)
  
  agehistogram <- ggplot(df, aes(x = Age)) +
    geom_histogram(bins = 23) +
    theme_minimal() +
    labs(title = paste("Age distribution for", status, "subjects"))
  
  print(agehistogram)
  
}

ggplot(FifteenMinutedataframe, aes(y = Age, x = Sample_Type)) +
  geom_boxplot() +
  stat_compare_means(method = "t.test") +
  theme_minimal()


```

The overall distribution looks overall normal and is fairly even between Konzo and Control. There is no significant difference between age in the control versus Konzo.

The next set of code will make a bi-axial plot between Age and RFU for the entire cohort, and both Konzo/Control broken up. And calculate an R value. If age is not a confounder, then we would expect R to not be significant.

```{r, ageinfopt2 , echo=FALSE, warning=FALSE, message=FALSE}

#Makes a basic biaxial plot comparing RFU to Age
ggplot(FifteenMinutedataframe, aes(x = Age, y = RFU)) +
  geom_point() +
  stat_cor(method = "pearson", label.x = 5, label.y = max(FifteenMinutedataframe$RFU, na.rm = TRUE)) +
  theme_minimal()

#Splits up the above into Konzo versus Control
for (status in Sample_Types) {
  df <- FifteenMinutedataframe %>% filter (Sample_Type == status)
  
  agebiaxialplot <- ggplot(df, aes(x = Age, y = RFU)) +
    geom_point() +
    stat_cor(method = "pearson", label.x = 5, label.y = max(FifteenMinutedataframe$RFU, na.rm = TRUE)) +
    theme_minimal() +
    labs(title = paste("Biaxial Age versus RFU plot for", status, "subjects"))
  
  print(agebiaxialplot)
  
}

```

Biaxial plot relating RFU to Age is signficant and decreasing. This may be skewed by older children being older cases. Argument that younger people have higher RFU is refuted by control group.

Just to double check that age isn't a problem, we are going to subsample the healthy and Konzo subjects and then run a t-test between the subsample. I will bootstrap this x number of times and then look at a distribution of p-values. This should give us a clear answer on whether or not age is too large of a confounder for the luminol test. 

```{r, agebinning and bootstrap, echo=FALSE, warning=FALSE, message=FALSE}

# Define parameters
n_bootstrap <- 500  # Number of bootstrap samples

#Creates age groups
FifteenMinutedataframe_agegrouped <- FifteenMinutedataframe %>%
  mutate(age_group = cut(Age, breaks = seq(min(Age), 22, by = 3), include.lowest = TRUE)) %>%
  filter(Age < 20)


#Figures out the minimum number of individuals for each group that can be pulled/pairs them
min_group_size_per_age <- FifteenMinutedataframe_agegrouped %>%
  group_by(age_group, Sample_Type) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(age_group) %>%
  summarise(min_count = min(count), .groups = "drop")

age_groups <- unique(min_group_size_per_age$age_group)

bootstrap_ttest <- function(data, min_counts) {
  
  subsampled_data <- data.frame()
  
  for (disease_status in Sample_Types) {
    for (age_profile in age_groups) {
      
      number_of_samples <- min_counts$min_count[which(min_counts$age_group == age_profile)]
      df <- data.frame()
      
      df <- data %>%
        filter(Sample_Type == disease_status) %>%
        filter(age_group == age_profile) %>%
        slice_sample(n = number_of_samples)

      subsampled_data <- rbind(subsampled_data, df)
    }
  }

    # Perform t-test
  t_test_result <- t.test(RFU ~ Sample_Type, data = subsampled_data)
  return(t_test_result$p.value)  # Return the p-value
}


# Run the bootstrapping with balanced sampling
bootstrap_results <- replicate(n_bootstrap, bootstrap_ttest(FifteenMinutedataframe_agegrouped, min_group_size_per_age), simplify = TRUE)

# Summarize bootstrap results
p_value_mean <- mean(bootstrap_results)  # Mean of p-values
p_value_sd <- sd(bootstrap_results)  # Standard deviation of p-values

# Print results
cat("Mean of bootstrap p-values:", p_value_mean, "\n")
cat("Standard deviation of bootstrap p-values:", p_value_sd, "\n")

# Optional: Plot the distribution of bootstrap p-values
hist(bootstrap_results, main = "Distribution of Bootstrap p-values", xlab = "p-value")

```

The next relevant thing to check is the order. I can do this by checking the order by splitting up village. I should look to see if there is a trend for Konzo and Control separately.


```{r, order by village, echo=FALSE, warning=FALSE, message=FALSE}

for (status in Sample_Types) {
  
  df <- FifteenMinutedataframe %>% filter(Sample_Type == status)
  
  orderplot <- ggplot(df, aes(x = Order, y = RFU)) +
    geom_point() +
    labs(title = paste("status by order for", status, "subjects")) +
    stat_cor(method = "pearson", label.x = 5, label.y = max(df$RFU, na.rm = TRUE)) +
    theme_minimal()
  
  print(orderplot)
  
}


```



This next set of boxplots look at the severity. Controls will be included on the graphs. However, excluded from the ANOVA for significance. All analysis will be done on the 15 minute timepoint.

```{r severity,echo=FALSE, warning=FALSE, message=FALSE}
#Make an overall boxplot by severity
ggplot(FifteenMinutedataframe, aes(x = Severity, y = RFU)) +
  geom_boxplot() +
  stat_compare_means(method = "anova") +
  theme_minimal()

SamplesPerSeverity <- clean_luminol_data %>% count(Severity)
kable(SamplesPerSeverity, caption = "Samples per Severity")

for (status in Sample_Types) {
  df <- FifteenMinutedataframe %>% filter (Sample_Type == status)
  
 statusboxplot <- ggplot(df, aes(x = Severity, y = RFU)) +
    geom_boxplot() +
    stat_compare_means(method = "anova") +
    stat_compare_means(method = "t.test", 
                     comparisons = list(c("Mild", "Moderate"), 
                                        c("Mild", "Severe"), 
                                        c("Moderate", "Severe")), 
                     label = "p.signif") +
    theme_minimal()

 
  print(statusboxplot)

  SamplesPerSeverity <- df %>% count(Severity)
  print(kable(SamplesPerSeverity, caption = paste("Samples per Severity for", status, "Subjects")))
  
}


```


A last analysis by sex

```{r sex, echo=FALSE, warning=FALSE, message=FALSE}

#Filter data for NAs
FilteredDataSex <- FifteenMinutedataframe %>% filter(!is.na(Sex))


ggplot(FilteredDataSex, aes(x = Sex, y = RFU)) +
  geom_boxplot() +
  stat_compare_means(method = "anova") +
  stat_compare_means(method = "t.test", comparisons = c("Male", "Female"), 
                     label = "p.signif") +
  theme_minimal()

  SamplesPerSex <- FifteenMinutedataframe %>% count(Sex)
  print(kable(SamplesPerSex, caption = "Samples per Sex"))
  
unique_sex <- unique(FilteredDataSex$Sex)

for (sex in unique_sex) {
  df <- FilteredDataSex %>% filter(Sex == sex)
  
  PlotbySex <- ggplot(df, aes(x = Sample_Type, y = RFU, fill = Sample_Type)) +
    geom_violin(show.legend = FALSE) +
    geom_boxplot(show.legend = FALSE, width = 0.2) +
    stat_compare_means(method = "t.test") +
    labs(title = paste("Boxplot by status for", sex, "subjects")) +
    theme_minimal()
  
  print(PlotbySex)
  
  SamplePerSex2 <- df %>% count(Sample_Type)
  print(kable(SamplePerSex2, caption = paste("Samples per Sex for", sex, "subject" )))
  
}

for (status in Sample_Types) {
  df <- FilteredDataSex %>% filter(Sample_Type == status)
  
  PlotbyStatus <- ggplot(df, aes(x = Sex, y = RFU)) +
    geom_violin(show.legend = FALSE) +
    geom_boxplot(width = 0.2) +
    stat_compare_means(method = "t.test") +
    labs(title = paste("Boxplot by sex for", status, "subjects")) +
    theme_minimal()
  
  print(PlotbyStatus)
}

#Just checking age difference between Konzo cases by Sex
FilteredDataSex_Konzo_only <- FilteredDataSex %>% filter (Sample_Type == "Konzo")
ggplot(FilteredDataSex_Konzo_only, aes(x = Sex, y = Age)) +
  geom_violin(show.legend = FALSE) +
  geom_boxplot(width = 0.2) +
  stat_compare_means(method = "t.test") +
  theme_minimal()
  

```


Males have a higher basal ROS production and less antioxidant potential than females
https://pmc.ncbi.nlm.nih.gov/articles/PMC5387169/
There may be something interesting happening with regards to age and sex. The last graph finds a significant difference in age between males and females with Konzo. The below epidemiological paper aligns with this finding. One possibility is that females are less likely to have a large amount of oxidative stress if they are younger. And once they begin having kids, they have less resilience to oxidative stress. Matt's paper did not have the same finding. But the max age for females was 12 and the average was 9. This may be too young to see the difference.
https://pubmed.ncbi.nlm.nih.gov/1959159/



To normalize for sex, I will be doing the same normalization by frequency of sex and then bootstrap the values.
```{r sexbinning and bootstrap, echo=FALSE, warning=FALSE, message=FALSE}
# Define parameters
n_bootstrap <- 500  # Number of bootstrap samples

counts_dataframe_for_sex <- data_frame(min_counts_sex = c( 60, 32), status = c("Control", "Konzo"))

bootstrap_ttest_sex <- function(data, counts) {
  
  subsampled_data <- data.frame()
  
  for (disease_status in Sample_Types) {
    for (sex in unique_sex) {
      
      number_of_samples <- counts$min_counts_sex[which(counts$status == disease_status)]
      df <- data.frame()
      
      df <- data %>%
        filter(Sample_Type == disease_status) %>%
        filter(Sex == sex) %>%
        slice_sample(n = number_of_samples)

      subsampled_data <- rbind(subsampled_data, df)
    }
  }

    # Perform t-test
  t_test_result <- t.test(RFU ~ Sample_Type, data = subsampled_data)
  return(t_test_result$p.value)  # Return the p-value
}


# Run the bootstrapping with balanced sampling
bootstrap_results_sex <- replicate(n_bootstrap, bootstrap_ttest_sex(FilteredDataSex, counts_dataframe_for_sex), simplify = TRUE)

# Summarize bootstrap results
p_value_mean_sex <- mean(bootstrap_results_sex)  # Mean of p-values
p_value_sd_sex <- sd(bootstrap_results_sex)  # Standard deviation of p-values

# Print results
cat("Mean of bootstrap p-values:", p_value_mean_sex, "\n")
cat("Standard deviation of bootstrap p-values:", p_value_sd_sex, "\n")

# Optional: Plot the distribution of bootstrap p-values
hist(bootstrap_results_sex, main = "Distribution of Bootstrap p-values", xlab = "p-value")

```
The p-values when controlling for the relative size of the Konzo/Control distribution by subsampling is still significant. 



Future things to do:
-Figure out how to print the KNITR better (one page per graph with information)/include more narrative.
-Think about possible "batch effect" problems

-Do analysis on recency

